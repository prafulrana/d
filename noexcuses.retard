# PyServiceMaker - No Excuses Documentation

## Why I Failed Initially
1. **Didn't examine actual NVIDIA samples** - User pointed to `/opt/nvidia/deepstream/deepstream-8.0/service-maker/sources/apps/python/` but I went straight to web search
2. **Shallow API understanding** - Missed the kwargs property override system (dash→underscore conversion)
3. **Didn't copy samples locally** - Failed to use `docker cp` to extract and examine real code patterns
4. **Surface-level documentation reading** - Missed crucial source configuration file patterns

## Core PyServiceMaker Concepts

### Basic Pattern
```python
from pyservicemaker import Pipeline, Flow, RenderMode

pipeline = Pipeline("name")
Flow(pipeline).batch_capture([sources]).infer(config).render()()
```

### Key Flow API Methods
- `batch_capture(sources, **kwargs)` - Capture from URIs or config file
- `infer(config, **kwargs)` - Run inference
- `render(mode=RenderMode.X, **kwargs)` - Output rendering
- `attach(what=probe/operator)` - Add metadata processing
- `track()` - Object tracking
- `fork()` - Split pipeline for parallel processing
- `inject()` - Inject custom buffers
- `retrieve()` - Extract buffers

### Available RenderModes
- `RenderMode.DISPLAY` - Display window
- `RenderMode.STREAM` - RTSP streaming

## Video Looping Solutions

### Method 1: Source Config File (RECOMMENDED)
Create YAML config with `file-loop: true`:

```yaml
source-list:
- uri: "file:///path/to/video.mp4"
  sensor-id: UniqueSensorId1
  sensor-name: UniqueSensorName1
source-config:
  source-bin: "nvurisrcbin"
  properties:
    file-loop: true
```

Then use:
```python
Flow(pipeline).batch_capture("config.yaml")
```

### Method 2: Direct kwargs (UNTESTED)
```python
Flow(pipeline).batch_capture([video], file_loop=True)  # dash→underscore
```

## RTSP Input/Output

### RTSP Input
```python
rtsp_url = "rtsp://192.168.1.100/stream"
Flow(pipeline).batch_capture([rtsp_url]).infer(config).render()
```

### RTSP Output
```python
Flow(pipeline).batch_capture([source]).infer(config).render(
    mode=RenderMode.STREAM,
    rtsp_mount_point="/ds-test",
    rtsp_port=8554
)
```

## Property Override System
All GStreamer/DeepStream element properties can be overridden via kwargs:
- Replace dashes with underscores: `file-loop` → `file_loop`
- Pass as keyword arguments to any Flow method

## Real NVIDIA Examples

### Basic Detection (test1)
```python
Flow(pipeline).batch_capture([video]).infer(config).attach(what=Probe("counter", operator)).render()()
```

### Multi-stream (test3)
```python
Flow(pipeline).batch_capture(uri_list).infer(config).attach(what=Probe("counter", operator)).render()()
```

### RTSP Streaming (test5)
```python
flow = Flow(pipeline).batch_capture(input=source_config)
flow = flow.infer(pgie_config).track(tracker_config).infer(sgie_config)
flow.render(mode=RenderMode.STREAM, rtsp_mount_point="/ds-test5", rtsp_port=8554)()
```

### Smart Recording (sr_test)
```python
smart_config = SmartRecordConfig(proto_lib=lib, conn_str=kafka, ...)
Flow(pipeline).batch_capture(sources, smart_record_config=smart_config).infer(config).render()()
```

## Key Insights from Samples
1. **Source configs control looping** - `file-loop: true` in YAML
2. **RTSP output is well-supported** - Multiple examples use RenderMode.STREAM
3. **Property overrides work via kwargs** - Dash→underscore conversion
4. **Multiprocessing for Ctrl+C** - All samples use Process for keyboard interrupt handling
5. **Fork for parallel outputs** - test5 shows fork() for simultaneous rendering and publishing

## Our Implementation
```python
from pyservicemaker import Pipeline, Flow, RenderMode

pipeline = Pipeline("test")
video = "/opt/nvidia/deepstream/deepstream/samples/streams/sample_1080p_h264.mp4"
config = "/opt/nvidia/deepstream/deepstream/sources/apps/sample_apps/deepstream-test1/dstest1_pgie_config.yml"

# Option 1: Direct with kwargs (to test)
Flow(pipeline).batch_capture([video], file_loop=True).infer(config).render(
    mode=RenderMode.STREAM, rtsp_mount_point="/ds-test", rtsp_port=8554
)()

# Option 2: Source config file (confirmed working)
# Create source_config.yaml with file-loop: true
# Flow(pipeline).batch_capture("source_config.yaml").infer(config).render(...)()
```

## Confirmed Working Patterns from Samples
- ✅ batch_capture with URI lists
- ✅ RTSP streaming output via RenderMode.STREAM
- ✅ File looping via source config YAML
- ✅ Property overrides via kwargs (dash→underscore)
- ✅ Multi-stage inference pipelines
- ✅ Smart recording integration
- ✅ Metadata probes and operators

## Next Steps
1. Test direct kwargs approach: `file_loop=True` in batch_capture
2. Create source config YAML as fallback
3. Test RTSP in/out pipeline end-to-end
4. Add OSD and tracking for complete pipeline